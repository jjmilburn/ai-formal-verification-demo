{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: AI + Formal Verification\n",
    "\n",
    "This notebook introduces the key thesis: **LLMs and formal verification are a perfect match**.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "AI-generated code is faster to write but harder to trust. Studies show:\n",
    "- 40% increase in bug rates with AI coding assistants (FormAI research)\n",
    "- 51% of GPT-3.5 generated C programs had vulnerabilities\n",
    "- We're generating code faster than we can review it\n",
    "\n",
    "## The Kleppmann Thesis\n",
    "\n",
    "From [Martin Kleppmann's prediction](https://martin.kleppmann.com/2025/12/08/ai-formal-verification.html):\n",
    "\n",
    "> \"Rather than having humans review AI-generated code, I'd much rather have the AI prove to me that the code it has generated is correct.\"\n",
    "\n",
    "Three forces are converging:\n",
    "1. **Cost reduction**: LLMs can draft proofs, dramatically lowering the cost of formal verification\n",
    "2. **Necessity**: AI-generated code needs *something* to replace human review\n",
    "3. **Synergy**: Proof checkers reject invalid proofs—hallucinations get caught and retried\n",
    "\n",
    "## Why This Matters for ML Practitioners\n",
    "\n",
    "If you work with LLMs, you know:\n",
    "- They hallucinate confidently\n",
    "- They're great at pattern matching, bad at reasoning\n",
    "- Output quality is probabilistic, not guaranteed\n",
    "\n",
    "Formal verification flips this:\n",
    "- A proof checker is **deterministic**: valid or invalid, no gray area\n",
    "- When the LLM hallucinates, the checker rejects it\n",
    "- The LLM can try again with the error message\n",
    "- Eventually, you get a **verified** solution\n",
    "\n",
    "## What We'll Demonstrate\n",
    "\n",
    "This project reproduces key findings from the [FM-ALPACA paper](https://arxiv.org/abs/2501.16207) (ACL'25), which benchmarked LLMs on formal verification across 5 languages.\n",
    "\n",
    "We'll show the same problem (binary search correctness) verified three ways:\n",
    "\n",
    "| Tool | What It Checks | Style |\n",
    "|------|---------------|-------|\n",
    "| **Dafny** | Pre/postconditions, loop invariants | Annotated imperative code |\n",
    "| **Lean4** | Mathematical theorems | Proof assistant / tactics |\n",
    "| **TLA+** | State machine properties | Model checking |\n",
    "\n",
    "## The Verification Loop\n",
    "\n",
    "The core pattern we demonstrate:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────┐\n",
    "│  1. LLM generates code/proof                │\n",
    "│         ↓                                   │\n",
    "│  2. Verifier checks it                      │\n",
    "│         ↓                                   │\n",
    "│  3a. If valid → Done! Proven correct.       │\n",
    "│  3b. If invalid → Feed error back to LLM   │\n",
    "│         ↓                                   │\n",
    "│  4. LLM fixes based on error               │\n",
    "│         ↓                                   │\n",
    "│  (repeat until valid or max attempts)       │\n",
    "└─────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "This loop is powerful because:\n",
    "- The verifier provides **precise feedback** (not vague \"looks wrong\")\n",
    "- LLMs are good at fixing code given specific error messages\n",
    "- The final result is **mathematically proven**, not just \"probably right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Check\n",
    "\n",
    "Let's verify the tools are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def check_tool(name, cmd):\n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n",
    "        print(f\"✅ {name}: found\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {name}: not found ({e})\")\n",
    "        return False\n",
    "\n",
    "print(\"Checking tool installations...\\n\")\n",
    "\n",
    "check_tool(\"Dafny\", [\"dafny\", \"--version\"])\n",
    "check_tool(\"Lean4\", [\"lean\", \"--version\"])\n",
    "\n",
    "tla_jar = os.path.expanduser(\"~/.tla/tla2tools.jar\")\n",
    "if os.path.exists(tla_jar):\n",
    "    print(f\"✅ TLA+ tools: found at {tla_jar}\")\n",
    "else:\n",
    "    print(f\"❌ TLA+ tools: not found at {tla_jar}\")\n",
    "\n",
    "print(\"\\nIf any tools are missing, run: ./setup.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the LLM client\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "\n",
    "client = LLMClient()\n",
    "print(f\"✅ LLM Client initialized (model: {client.model})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Continue to the demo notebooks:\n",
    "\n",
    "1. **[02-dafny-demo.ipynb](02-dafny-demo.ipynb)** - LLM generates Dafny annotations\n",
    "2. **[03-lean4-demo.ipynb](03-lean4-demo.ipynb)** - LLM generates Lean4 proofs\n",
    "3. **[04-tlaplus-demo.ipynb](04-tlaplus-demo.ipynb)** - LLM generates TLA+ specs\n",
    "4. **[05-comparison.ipynb](05-comparison.ipynb)** - Side-by-side evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
