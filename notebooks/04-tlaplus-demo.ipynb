{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLA+ Demo: LLM-Assisted Specification\n",
    "\n",
    "**TLA+** is a formal specification language for concurrent and distributed systems. Unlike Dafny and Lean, TLA+ uses **model checking**: it exhaustively explores all possible states to find bugs.\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. See what a TLA+ specification looks like\n",
    "2. Ask an LLM to generate a spec from natural language\n",
    "3. Run TLC (the model checker) to find counterexamples\n",
    "4. Feed counterexamples back to the LLM to fix the spec\n",
    "\n",
    "## Why TLA+?\n",
    "\n",
    "TLA+ is used at Amazon, Microsoft, and other companies for distributed systems:\n",
    "- AWS uses it to verify DynamoDB, S3, and other services\n",
    "- It catches subtle concurrency bugs that testing misses\n",
    "- The \"genefication\" workflow (from [Murat Demirbas's blog](https://www.mydistributed.systems/2025/01/genefication.html)) shows how LLMs can draft TLA+ specs\n",
    "\n",
    "## The Genefication Workflow\n",
    "\n",
    "```\n",
    "English description\n",
    "       â†“\n",
    "LLM generates TLA+ spec\n",
    "       â†“\n",
    "TLC model checker runs\n",
    "       â†“\n",
    "   â”Œâ”€â”€â”€â”´â”€â”€â”€â”\n",
    "   â†“       â†“\n",
    "  Pass   Counterexample found\n",
    "   â†“           â†“\n",
    " Done    Feed counterexample to LLM\n",
    "               â†“\n",
    "         LLM fixes spec\n",
    "               â†“\n",
    "         (repeat)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.verifiers import TLCVerifier\n",
    "from rich import print as rprint\n",
    "from rich.syntax import Syntax\n",
    "from rich.panel import Panel\n",
    "\n",
    "client = LLMClient()\n",
    "\n",
    "try:\n",
    "    verifier = TLCVerifier()\n",
    "    print(\"âœ… Client and TLC verifier ready\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"âš ï¸ TLA+ tools not installed: {e}\")\n",
    "    print(\"Run ./setup.sh to install TLA+ tools\")\n",
    "    verifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Mutual Exclusion\n",
    "\n",
    "Let's start with the classic: Peterson's algorithm for mutual exclusion.\n",
    "\n",
    "**Problem**: Two processes want to access a critical section. We need to ensure:\n",
    "1. **Safety**: They never both enter at the same time\n",
    "2. **Liveness**: If a process wants in, it eventually gets in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reference implementation\n",
    "with open('../examples/tlaplus/MutualExclusion.tla') as f:\n",
    "    mutex_spec = f.read()\n",
    "\n",
    "rprint(Panel(Syntax(mutex_spec, 'text', theme='monokai'), title=\"Peterson's Algorithm in TLA+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify with TLC\n",
    "if verifier:\n",
    "    with open('../examples/tlaplus/MutualExclusion.cfg') as f:\n",
    "        config = f.read()\n",
    "    \n",
    "    result = verifier.verify(mutex_spec, config)\n",
    "    print(f\"Verification: {'âœ… PASSED' if result.success else 'âŒ FAILED'}\")\n",
    "    if not result.success:\n",
    "        print(f\"Counterexample:\\n{result.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Specs from Natural Language\n",
    "\n",
    "Now let's ask the LLM to generate a TLA+ spec from scratch, given only an English description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "Design a simple counter system with the following properties:\n",
    "\n",
    "1. There is a counter variable that starts at 0\n",
    "2. Two processes can increment the counter\n",
    "3. The counter should never exceed 5\n",
    "4. Each process can only increment when it's their turn\n",
    "5. Processes take turns (alternating)\n",
    "\n",
    "Verify:\n",
    "- Safety: counter never exceeds 5\n",
    "- The system can make progress (liveness)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Description:\")\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genefication_loop(description: str, max_attempts: int = 5):\n",
    "    \"\"\"Run the genefication workflow: LLM generates, TLC checks, iterate.\"\"\"\n",
    "    \n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Attempt {attempt}/{max_attempts}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Ask LLM to generate/fix spec\n",
    "        if attempt == 1:\n",
    "            print(\"\\nðŸ“¤ Asking LLM to generate TLA+ spec...\")\n",
    "            response = client.generate_tlaplus_spec(description)\n",
    "        else:\n",
    "            print(f\"\\nðŸ“¤ Asking LLM to fix based on counterexample...\")\n",
    "            response = client.generate_tlaplus_spec(description, error=result.error)\n",
    "        \n",
    "        spec = client._extract_code(response.content)\n",
    "        print(f\"   Tokens used: {response.input_tokens + response.output_tokens}\")\n",
    "        \n",
    "        rprint(Panel(Syntax(spec, 'text', theme='monokai', line_numbers=True), \n",
    "                     title=f\"Generated Spec (Attempt {attempt})\"))\n",
    "        \n",
    "        if verifier is None:\n",
    "            print(\"âš ï¸ TLC not available, showing LLM output only\")\n",
    "            return spec, attempt\n",
    "        \n",
    "        # Verify with TLC\n",
    "        print(\"\\nðŸ” Running TLC model checker...\")\n",
    "        result = verifier.verify(spec)\n",
    "        \n",
    "        if result.success:\n",
    "            print(\"\\nâœ… MODEL CHECKING PASSED!\")\n",
    "            return spec, attempt\n",
    "        else:\n",
    "            print(f\"\\nâŒ Model checking found issue:\")\n",
    "            print(result.error[:1000])  # Truncate long counterexamples\n",
    "    \n",
    "    print(f\"\\nâš ï¸ Max attempts ({max_attempts}) reached\")\n",
    "    return spec, max_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the genefication loop\n",
    "final_spec, attempts = genefication_loop(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How TLA+ Differs\n",
    "\n",
    "| Aspect | Dafny/Lean | TLA+ |\n",
    "|--------|-----------|------|\n",
    "| Verification | Theorem proving | Model checking |\n",
    "| Feedback | Proof obligations | Counterexamples (traces) |\n",
    "| Strength | Proofs are general | Finds actual bug scenarios |\n",
    "| Weakness | May need complex invariants | State space explosion |\n",
    "| LLM use | Generate proofs/tactics | Generate entire specs |\n",
    "\n",
    "## Key Insight: Counterexamples are Gold\n",
    "\n",
    "TLC's counterexamples are incredibly useful for LLMs:\n",
    "- They show a **concrete execution trace** that violates the property\n",
    "- The LLM can see exactly which state transition caused the problem\n",
    "- This is more actionable than abstract proof obligations\n",
    "\n",
    "## From the FM-ALPACA Paper\n",
    "\n",
    "The [FM-ALPACA benchmark](https://arxiv.org/abs/2501.16207) includes TLA+ as one of five languages:\n",
    "\n",
    "> \"We constructed 18k high-quality instruction-response pairs across five formal specification languages (Coq, Lean4, Dafny, ACSL, and **TLA+**).\"\n",
    "\n",
    "TLA+ is particularly interesting because:\n",
    "- It's used in industry more than academic proof assistants\n",
    "- The model checking feedback loop is natural for LLMs\n",
    "- PlusCal (an algorithmic notation that compiles to TLA+) is more intuitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: Comparison\n",
    "\n",
    "Continue to [05-comparison.ipynb](05-comparison.ipynb) to see a side-by-side evaluation of all three tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
